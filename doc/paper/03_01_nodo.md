## Nodo de roteamento com *Actor Model*
\label{n2:nodo_actor}

O programa foi desenvolvido sobre o protocolo P2P específico para o *Bitcoin*, conforme informado no~\REF{n3:proto_node}. Este protocolo é divido em duas partes: topologia do nodo em \REF{n3:nodo_topologia_actor} -- e em \REF{n3:proto_nodo} -- no qual a primeira refere-se apenas à topologia escolhida  para tratar do assincronismo, e a segunda é referente às funcionalidades esperadas por um programa que interaja com a rede do *Bitcoin*.

### Topologia do programa em *Actor Model*
\label{n3:nodo_topologia_actor}

O programa quando em execução é um potencial nodo -- cliente/servidor -- da rede *Peer-to-Peer* do *Bitcoin*. Como um *actor*, mantém três interfaces: escrita do *log* em um arquivo; escuta por novas conexões *TCP* por aplicações *telnet* para administradores do programa em uma porta; e escuta por novas conexões *TCP* por aplicações de outros nodos em outra porta. O seu comportamento, ao receber novas conexões administrativas ou de nodos, é o de criar *actors* de *admin* e de *peer*, respectivamente. Para evitar ambiguidade, é utilizado "nodo"{} para designar um programa executando em algum computador e "*peer*"{} para designar a representação interna (*actor*) de um programa executando em um computador externo.

#### *Actors* em uma rede P2P
\label{n3:actors_p2p}

\begin{figure}[!ht]
	\centering
	\caption{Usuários e *actors* em nodos diferentes.}
	\includegraphics[width=0.7\textwidth]{peers.png}
	\begin{minipage}{\textwidth}
		\centering
		{\small Fonte: Os Autores (2018).}\par
	\end{minipage}
	\label{fig:nodos}
\end{figure}

Na~\REF{fig:nodos} -- é mostrado uma topologia de conexão entre três nodos, e cada administrador, de uma cor, controla um nodo da mesma cor. Cada nodo mantém um *actor* do seu administrador, uma representação interna ao nodo. O nodo azul mantém uma conexão com os outros nodos, e representa cada um dos outros nodos através de *actors*, e os outros nodos criam tais representações de forma semelhante. 

As informações salvas no arquivo de *log* são interferidas por *macros* na qual podem, através do compilador padrão, informar o horário, módulo, nível de depuração[^20], arquivo e linha em que o comando se encontra no código.[^21] Para isto as *macros* expandem em código que contém tais informações, efeito que contribui para a produtividade do desenvolvimento do programa.

[^20]: *Logs* podem ser completamente omitidos de forma seletiva de acordo com o seu nível de depuração.

[^21]: Exemplo:

    `[17:40:32][btc][INFO] [/main.rs:101] New admin connection: V4(127.0.0.1:60916)`.

#### Topologia Simplificada
\label{n4:topologia_simpl}

Para a análise da topologia de interação entre os *actors* internos ao sistema, convém uma representação gráfica delineando todos os tipos de *actors* e seus canais de comunicação.

Os canais de comunicação entre *actors* distintos são representados por uma seta unidirecional, no qual o *actor* que inicia a mensagem é chamado de "ativo", e o que recebe a mensagem é chamado de "reativo". Se a seta do canal é tracejada, então o *actor* reativo irá gerar uma resposta às mensagens iniciadas pelo *actor* ativo através de um canal temporário de uso único. Os canais são representados por variáveis e são constituídos por partes transmissores e receptoras. Portanto os escopos (e atores) que podem transmitir e receber por um canal é determinado em tempo de compilação.

\begin{figure}[!ht]
	\centering
	\caption{Nodo simplificado utilizando *Actor Model*.}
	\includegraphics[width=0.7\textwidth]{server_simples.png}
	\begin{minipage}{\textwidth}
		\centering
		{\small Fonte: Os Autores (2018).}\par
	\end{minipage}
	\label{fig:nodo_simples}
\end{figure}

A~\REF{fig:nodo_simples} -- representa as principais interações entre os *actors* do sistema. Pela natureza isolada de *actors*, a interferência ou o compartilhamento de informação acontece exclusivamente por comunicação através de canais de mensagens.

Os *admins*/*peers* têm comunicações ativa e reativa, através de sockets, com os usuários ou o nodos externos. Tem também duas comunicações ativas com o *scheduler*, uma para enviar pedidos de processamento e outra para fins de cadastro internos do sistema. Finalmente, tem também uma comunicação reativa do *router*, caso algum *worker* queira enviar-lhe alguma mensagem.
O *scheduler* tem comunicações ativas para os *workers* e o *router*, e comunicações reativas do *blockchain* e dos *admins*/*peers*.
Os *workers* têm comunicações ativas com o *router* e *blockchain*, e comunicação reativa do *scheduler*.
O *router* tem comunicações ativas com cada *admin*/*peer*, e comunicações reativas dos *workers* e do *scheduler*, este último para fins administrativos.
O *blockchain* tem comunicação ativa com o *scheduler* e comunicações reativas dos *workers*.

Com esta topologia de comunicação, distribuição de execução e acesso a dados, muitas execuções concorrentes são possíveis entre *workers* diferentes e o *blockchain*, desde que não precisem de um acesso exclusivo a uma mesma memória ou recurso.

O *scheduler*, em particular, é criado na inicialização do programa e termina apenas na terminação geral do programa, e uma de suas funções é coordenar os pedidos de execuções -- assíncronos e concorrentes -- que serão enviados pelos demais *actors*, que podem ter especificações de prioridade e sempre esperam por alguma resposta. Outra importante tarefa do *scheduler* é executar a política de criação, remoção e utilização de *workers*, *actors* que apenas executam o que lhes é pedido e produzem uma resposta de forma assíncrona.
De forma semelhante, o *router* e o *blockchain* são criados na inicialização do programa e não têm previsão para término senão na terminação do programa. O primeiro tem por principal função fornecer uma comunicação com qualquer *admin*/*peer* conectado ao nodo. Já o segundo, tem por principal função o gerenciamento e interface para os dados dos blocos, transações e suas cadeias.

#### Topologia Completa
\label{n4:topologia_compl}

\begin{figure}[!ht]
	\centering
	\caption{Nodo utilizando *Actor Model*.}
	\includegraphics[width=0.7\textwidth]{server_completo.png}
	\begin{minipage}{\textwidth}
		\centering
		{\small Fonte: Os Autores (2018).}\par
	\end{minipage}
	\label{fig:nodo_completo}
\end{figure}

A~\REF{fig:nodo_completo} -- representa as principais interações entre os *actors* do sistema de forma mais detalhada. Destaca componentes envolvidos nas comunicações ativas (componentes "w"{} -- *writers* -- ou "tx"{} -- transmissores) e nas comunicações reativas (componentes "r"{} -- *readers* -- ou "rx"{} -- receptores). As setas internas a um mesmo *actor* representam meramente fluxo de dados que existem entre a separação lógica dos componentes, ou seja, não representam envio de mensagens através de canais.

##### *Admins* e *Peers*
\label{n5:admin_peers}

O nodo não demanda que, antes ou após a inicialização, existam algum *worker*, nenhum *admin* e nenhum *peer*, mas apenas o *scheduler*, o *router*, o *blockchain* e o *actor* do nodo[^50]. O *actor* do nodo recebe as novas conexões TCP em portas específicas, e inicia a configuração de um novo *actor*. Seja um administrador ou um outro nodo, este *admin/peer actor*, de início, tem três canais que existirão ao longo da existência do próprio *admin/peer actor*: *chn msg r* (azul), *sched w* (preto) e *chn reg w* (verde). O primeiro canal possibilita que o *admin/peer actor* receba mensagens enviadas por um *worker*, por meio do *router*, *e.g.* como um efeito de um pedido realizado por um *admin*. O segundo canal permite que o *peer* envie pedidos de execução que serão realizados pelos *workers*. 

[^50]: Este ator não é representado nas figuras mas pode receber novas conexões TCP e tem um canal de comunicação com o *router*. Sua única função é realizar o cadastro de conexões que são iniciadas por outros nodos. Futuramente, existe a intenção de formalizar este ator em um arquivo separado no código do programa.

Já o último canal tem uma função administrativa perante o *scheduler*, utilizado somente em momentos de cadastramento ou descadastramento de *actors*. É com o uso deste canal que um *admin* pode solicitar uma nova conexão com outro nodo, ao realizar um pedido a um *worker* que, em sucesso, cria uma conexão TCP e um novo *peer*. Como o *worker* deverá cadastrar este *peer* no *router*, o *admin* envia junto ao próprio pedido uma cópia da capacidade de transmissão[^51] do canal *mpsc* (*multiple producer, single consumer*) de des/cadastro. O *worker*, nesta situação, não guarda esta capacidade de des/cadastro consigo, mas a transfere para o novo *peer* que está sendo criado. Também é com o uso deste canal que o *admin/peer* podem se descadastrar junto ao *router*.[^52]
Dado esta dinâmica possibilitada pelos pedidos, a topologia do nodo é controladamente variável, pois existem possibilidades de interações temporárias/momentâneas.

[^51]: Portanto, em execução, a topologia pode diferir, de maneira controlada, daquela mostrada nas figuras de topologia.

[^52]: Devido ao fato de que não há interação com *actors* senão por mensagens, eles devem se encarregar de seu próprio descadastro, liberação de recursos e sua própria destruição de acordo com sua reação a mensagens específicas.

Cada pedido realizado por um *admin/peer* implica uma resposta, mesmo que ela não seja significativa para o *admin/peer*. Ao elaborar o pedido, o *actor* cria um canal *oneshot*[^25], armazena a capacidade de receber o valor que será transmitido pelo canal (canal não demonstrado na figura) e envia a capacidade de transmitir o valor junto ao próprio pedido (não demonstrado na figura mas armazenado no *scheduler*, no *Inbox*).

[^25]: De uso único.

##### *Scheduler*
\label{n5:sched}

O *scheduler* é o *actor* de interface entre os *admin/peer*, o *blockchain* e os *workers*, e também um *actor* que, no des/cadastramento de novos *admins/peers*, realiza comunicações administrativas com o *router*. Ele recebe vários pedidos de vários *admins/peers* e do *blockchain* através do *sched r* (em preto), lida com a carga de trabalho dos *workers* e também com a sua criação e destruição (mostrado como o componente *select*, em preto), encaminha os pedidos aos *workers* através dos *exec w* (em preto), recebe a resposta dos *workers* através de canais *oneshots* (armazenados no *Outbox*, porém não mostrados na figura) e encaminha as respostas de volta para os *admins/peers* ou *blockchain* através de canais *oneshots* (armazenados no *Inbox*, mas não representados na figura).

No *scheduler*, o *Inbox* representa uma listagem de vários canais referentes a cada *admin/peer* ou *blockchain*: um *sched r* para cada *peer/admin* e um *oneshot* (não representado na figura) para cada resposta esperada por cada *admin/peer* ou *blockchain*[^27]. O *Outbox* representa uma listagem de vários canais referentes a cada *worker*: um *exec w* para cada *worker* e um *oneshot* (não representado na figura) para cada pedido em execução, ou em fila de execução, por cada *worker*.[^28]

[^27]: Um *admin/peer* ou *blockchain* pode realizar vários pedidos e esperar por todos eles ao mesmo tempo, mantendo vários *oneshots* consigo.

[^28]: Um *worker* contêm uma fila de pedidos, mas executa um pedido por vez. Este arranjo permite que exista uma reserva de *workers* com uma reserva de *threads* com uma reserva de *cores* de processamento para execuções prioritárias, caso seja de interesse do gerenciador do nodo.

O *scheduler* também armazena dois transmissores administrativos que são utilizados por *worker* e *admin/peer* para o *router* e o *blockchain*, que são clonados na criação de novos *actors*.

Por fim, o *scheduler* não interpreta nenhum pedido ou resposta. Isto simplifica a elaboração, execução concorrente e reutilização de pedidos por diferentes *actors*. Pelo fato do *scheduler* não precisar fazer esta interpretação, o *workflow* dos pedidos e respostas é simplificado, e o comportamento dos *actors* se torna mais previsível.

##### *Router*
\label{n5:router}

O *router* tem a função de receber mensagens dos *workers* (através do *router r*, em preto) e encaminhar pedidos ou mensagens para *admins/peers* específicos, uma vez que possui a estrutura chamada de *Peer Messenger* que pode transmitir para cada *admin/peer*, inclusive em *broadcast* (através dos *chn msg w*). O *router* também tem um canal receptor para fins administrativos (através do *chn msg w*, em azul), sendo este utilizado para realizar o des/cadastro dos atores do *admins/peers*.

O *Peer Messenger* tem uma parte transmissora de vários canais, um para cada *admin/peer*. Por exemplo, quando um *admin* requisita a desconexão e remoção de um *peer*, um *worker* recebe e executa este pedido do *admin*, e retorna uma resposta a ele. Antes de responder, o *worker* realiza um pedido para o *router* para que o mesmo encaminhe o pedido de remoção de alta prioridade para o *peer* especificado. O *peer*, ao receber o pedido, se prepara para se remover: entra em um estado neutro (ver o estado *standby* em \REF{n4:mach_peer_actor}) e inicia alguns procedimentos internos a ele, como esperar a finalização das mensagens que já estavam em vigor. Ao entrar em um estado seguro para sua destruição, inicia um desencadeamento administrativo com o *scheduler* para o descadastro de canais referentes a este *peer*. O *scheduler* propaga tal intenção para o *router*, que também realiza alguns descadastros. Finalmente, o *peer* tem seus recursos desalocados e liberados, como seu uso de *sockets*.

##### *Worker*
\label{n5:worker}

O *worker* é um *actor* que interage com o *scheduler*, *blockchain* e *router*, sendo este último utilizado para interagir indiretamente com os *admins/peers*. Ele mantém uma lista de pedidos a serem executados e executa o que for de maior prioridade. Após cada execução, o *worker* adquire pedidos novos enviados a ele pelo *exec r* (em preto), os ordenando na lista de pedidos. Depois da execução, prepara a resposta e a envia através do *shot w* (em lilás), no qual cada pedido é tratado isoladamente -- o *worker* não tem alteração interna de estado como efeito de um pedido --, sendo desestruturado e então interpretado.

Ao longo de um procedimento de uma tarefa, o *worker* pode interagir com o *router* a fim de aquisição de informações sobre a lista de *admins/peers* que estão conectados, bem como realizar mensagens para serem propagadas para qualquer *admin/peer*. Além disto, pode também interagir com o *blockchain*, enviando informações que são consideradas imprevistas ou administrativas.

Futuramente, espera-se que novos tipos de *actors* existirão, e que poderão interagir com os canais do *router*. Neste caso, os *workers* poderão precisar de uma implementação por máquina de estado para que possam interagir com novos *actors* de forma assíncrona.

##### *Blockchain*

O *blockchain* é um *actor* que realiza procedimentos exclusivamente referente aos dados da *blockchain* do *Bitcoin*. Comporta-se através de uma máquina de estados e tem canais semelhantes aos *admins/peers*, no qual pode receber mensagens informativas ou administrativas (através do *bchain r*, em preto) ou indiretamente enviar pedidos aos *workers* (através do *sched w*, em preto). 

Este *actor* tem seu comportamento definido por uma máquina de estados, porém sua implementação está em esboço.

### Comportamento do Programa
\label{n3:proto_nodo}

O protocolo na implementação do nodo é dividido em três partes: *codec*, *peer actor* -- representação interna de nodos externos -- e *admin actor* que é a representação do usuário administrador conectado ao nodo, e por meio deste serão executados os comandos referentes à carteira.

#### *Codec*
\label{n4:nodo_codec}

O *codec* é um componente que gerencia o *socket* e realiza a abstração de dados, sendo assim, é preciso existir um tipo de *codec* para cada tipo de *actor* diferente que interage com um *socket*, um para o *admin* e outro para o *peer*. O *codec* do *admin* não possui funções de abstração de dados, pois apenas lida com a interface *telnet*, sendo assim apenas realiza a leitura do *socket* e gera um *string* até ler uma quebra de linha e quando necessário envia no *socket* uma *string*, utilizado para *feedback*.

O *codec* do *peer* trabalha com um *socket* direto com outro nodo onde as mensagem estão em bytes, e ele realiza o processo de abstração desta mensagem em estruturas que possuem significado (mais alto nível). A codificação ocorre apenas na construção de mensagem feita pelo *actor* do *worker* e a decodificação é feita ao receber uma mensagem no *socket*, ocorre quando o nodo referente àquele *peer* manda uma mensagem para o nodo.

O processo de decodificação começa quando chega uma quantidade de bytes no *socket* do *peer*, então é verificado se existem pelo menos 24 bytes de informação (tamanho do *header*) e caso existam é verificado se os bytes referentes a cada uma das variáveis do *header* está dentro do esperado[^2] e com estas variáveis é construído o *header*. Com o valor da variável *payload size* será lido esta quantidade exata de bytes do *socket*, caso existam, e se os *checksums*[^1] forem iguais é criado a abstração do *payload* e assim acaba o processo, pois já existe as abstrações necessárias para se construir a mensagem abstraída.

[^2]: As variáveis *command* e *magic bytes* possuem um conjunto definido de valores.

[^1]:*Payload* *checksum* informado no *header* e *checksum* do *payload* lido.

O processo de codificação é iniciado quando chega no canal do *worker* uma tarefa de envio de mensagem para algum nodo, é criado a abstração do *payload*, feita de acordo com o comando especificado, e gerado os bytes deste *payload* assim é calculado o seu *checksum* e seu tamanho e gerado a abstração do *header* a partir destas informações, agora é necessário apenas gerar o hexadecimal do *header*, a mensagem serializada é a concatenação do hexadecimal do *header* e do *payload*.

#### *Peer Actor*
\label{n4:mach_peer_actor}

Sempre quando é iniciado uma nova conexão com algum nodo é criado um *peer*, e após isto é iniciado a máquina de estados deste *actor*. 
Nesta máquina o seu estado inicial, chamado de *standby*, fica à espera de alguma notificação do *codec*. 
Assim que é recebido esta notificação são tratados os três canais que ele possui: o do *socket*, o do *scheduler*, canal que possui o *feedback* do *worker* em relação ao pedido realizado e pode ter a sua mensagem ignorada[^3], e o do *router*, canal referente às tarefas que o *peer* deve realizar, enviadas diretamente pelo *worker*[^4].

No estado de *standby*, após ser recebido qualquer notificação, são descartados todas as respostadas provenientes do *scheduler* e é verificado o conteúdo enviado pelo *router* e são executadas todas as tarefas existentes nele. A maioria das tarefas serão com relação ao envio de mensagem para o nodo relativo ao *peer*, no entanto mensagens diferentes precisam ser tratadas de forma diferentes, de acordo com o protocolo do *Bitcoin*, por exemplo, caso seja recebido uma tarefa de *ping* é necessário que seja esperado uma mensagem de resposta de *pong* do nodo.

Como existem diversos tipos de comandos e de protocolos, que podem ser demasiadamente complexos, é trocado de estado e este novo estado definirá como deverá ser a resposta e o que deverá ser esperado. Para os procedimentos mais complexos é iniciado um estado que iniciará uma nova máquina de estados interna para tratá-los, facilitando assim o entendimento. 

[^3]: A mensagem pode ser ignorada pois este retorno não é a resposta de nenhuma ação e sim das comunicações, portanto não há necessidade de ser enviada para o outro nodo ou informado no servidor.

[^4]: Um exemplo de tarefa é a *rawmsg*, onde deve ser enviado a mensagem hexadecimal recebida neste canal para o *socket*.

Uma máquina de estados interna define o comportamento necessário para se realizar o *handshake*, segundo os parâmetros estabelecidos pelo protocolo da rede de *Bitcoin*, visto que este é um comportamento mais complexo que demanda de três estados bem distintos e com tomadas de decisões. Na~\REF{fig:handshake} -- é mostrada esta representação, sempre que é iniciada a conexão com um novo nodo é dado início nesta máquina, sendo possível existir duas situações: quando o nodo em si iniciou a conexão ou quando um nodo externo iniciou a conexão TCP -- situações representadas pelos diferentes caminhos após a pergunta "*Starting Connection?*".

\begin{figure}[!ht]
	\centering
	\caption{Maquina de estados do *Handshake*}
	\includegraphics[width=0.7\textwidth]{handshake.png}
	\begin{minipage}{\textwidth}
		\centering
		{\small Fonte: Os Autores (2018).}\par
	\end{minipage}
	\label{fig:handshake}
\end{figure}

Caso o nodo inicie o processo, é feito um pedido de criação da mensagem de "*Version*"{} para um *worker* e assim que ele retorna tal mensagem ela é enviada para o respectivo nodo e então é trocado de estado. No próximo estado o *peer* fica esperando até receber ambas as mensagens de reconhecimento da mensagem de "*Version*"{} -- chamada de "*Verack*"{} -- como da mensagem de "*Version*"{} do nodo ao qual está se conectando, caso ambas as mensagens forem recebidas e estejam válidas é pedido para o *worker* criar a mensagem de "*Verack*"{} do nodo externo assim que o *worker* retorna esta mensagem ela é enviada para o nodo e finalizado a máquina de estados.

Caso a conexão seja iniciada pelo próprio nodo, ou seja, quando é recebida uma mensagem válida de "*Version*"{} é feito um pedido ao *worker* do "*Verack*"{} desta mensagem de "*Version*"{} e também da mensagem de "*Version*"{} do nodo em si, assim que o *worker* retorna ambas estas mensagens elas são enviadas para o nodo que iniciou o processo e é trocado o estado desta máquina interna. Neste novo estado é esperado uma mensagem de "*Verack*", relacionado a mensagem de "*Version*"{} enviada previamente, quando chega esta mensagem e ela é válida o processo de *handshake* é finalizado com sucesso.

Com exceção do *handshake*, que é realizado apenas uma vez no momento de inicialização da máquina de estados do *peer*, todos os procedimentos são cíclicos, terminando apenas quando a conexão *peer*-nodo acaba.

#### *Admin Actor*
\label{n4:mach_admin_actor}

De maneira similar ao *actor* do *peer*, existe uma máquina de estados para controlá-lo com a diferença de que a sua conexão não é com um nodo de *Bitcoin* mas sim com uma interface *telnet*. Assim, este também permanece no estado inicial esperando alguma notificação do *codec*. Este *actor*, no entanto, possui apenas dois canais de comunicação: o do *scheduler*, sendo que o *feedback* do *scheduler* neste caso é importante[^5], e o do *socket*.

[^5]: Informar os resultados do comando executado pelo *worker* na interface *telnet*.

Quando chega alguma informação no *socket* do *admin* gerenciado pelo *codec*, a máquina é notificada e inicializa o procedimento. O primeiro passo é a comparação interna, derivada pela *crate struct-opt*, da *string* obtida com o argumento enviado pelo administrador e, caso sejam iguais, é criado a estrutura da requisição e é modificado de estado. Caso contrário, é apresentado o *help* do comando que falhou de volta para o administrador.

Na maioria dos casos o pedido do *admin* possui um *workflow* simples, onde é enviado uma requisição ao *scheduler* e ele espera o *feedback* para enviar ao *codec*. Após isto, ele retorna ao estado inicial e, para estes casos, é definido um estado chamado de *simpleWait* que define este comportamento. Para o restante dos casos, assim como na máquina do *peer*, é criado um estado para cada tipo de pedido e, caso exista um muito complexo, é utilizada uma máquina de estados interna.

